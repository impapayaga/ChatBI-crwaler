# 系统架构说明

## 整体架构图

```
┌─────────────────────────────────────────────────────────────┐
│                    政策文件爬取与AI总结系统                    │
├─────────────────────────────────────────────────────────────┤
│                                                             │
│  ┌─────────────┐    ┌─────────────┐    ┌─────────────┐     │
│  │   爬虫模块   │    │   AI总结模块  │    │   定时任务   │     │
│  │  crawler.py │    │ai_summarizer │    │ scheduler.py │     │
│  └─────────────┘    └─────────────┘    └─────────────┘     │
│         │                   │                   │          │
│         ▼                   ▼                   ▼          │
│  ┌─────────────────────────────────────────────────────────┐ │
│  │                数据库层 (SQLite)                        │ │
│  │  ┌─────────────┐  ┌─────────────┐  ┌─────────────┐    │ │
│  │  │ 政策文件表   │  │  AI总结表   │  │  配置表     │    │ │
│  │  │PolicyFile  │  │AISummary   │  │CrawlConfig │    │ │
│  │  └─────────────┘  └─────────────┘  └─────────────┘    │ │
│  └─────────────────────────────────────────────────────────┘ │
│         │                   │                   │          │
│         ▼                   ▼                   ▼          │
│  ┌─────────────────────────────────────────────────────────┐ │
│  │                API接口层 (FastAPI)                     │ │
│  │  ┌─────────────┐  ┌─────────────┐  ┌─────────────┐    │ │
│  │  │  爬取接口   │  │  总结接口   │  │  数据接口   │    │ │
│  │  │/api/crawl  │  │/api/summarize│ │/api/summaries│   │ │
│  │  └─────────────┘  └─────────────┘  └─────────────┘    │ │
│  └─────────────────────────────────────────────────────────┘ │
│         │                   │                   │          │
│         ▼                   ▼                   ▼          │
│  ┌─────────────────────────────────────────────────────────┐ │
│  │                前端展示层 (HTML/JS)                    │ │
│  │  ┌─────────────┐  ┌─────────────┐  ┌─────────────┐    │ │
│  │  │  数据展示   │  │  操作控制   │  │  统计信息   │    │ │
│  │  │  政策列表   │  │  爬取按钮   │  │  数据统计   │    │ │
│  │  └─────────────┘  └─────────────┘  └─────────────┘    │ │
│  └─────────────────────────────────────────────────────────┘ │
└─────────────────────────────────────────────────────────────┘
```

## 数据流程

### 1. 爬取流程
```
目标网站 → 爬虫模块 → 关键词过滤 → 数据库存储 → 标记未处理
```

### 2. AI总结流程
```
未处理政策 → AI总结模块 → API调用 → 结果解析 → 总结存储
```

### 3. 前端展示流程
```
前端请求 → API接口 → 数据库查询 → 数据返回 → 前端展示
```

### 4. 自动调度流程
```
定时器触发 → 执行爬取 → 执行AI总结 → 更新配置 → 等待下次执行
```

## 自动调度系统

### 调度器架构
```
┌─────────────────────────────────────────────────────────────┐
│                    定时调度系统                              │
├─────────────────────────────────────────────────────────────┤
│                                                             │
│  ┌─────────────┐    ┌─────────────┐    ┌─────────────┐     │
│  │   调度器    │    │   任务执行   │    │   状态管理   │     │
│  │ scheduler.py│    │ 爬取+总结   │    │ 执行记录     │     │
│  └─────────────┘    └─────────────┘    └─────────────┘     │
│         │                   │                   │          │
│         ▼                   ▼                   ▼          │
│  ┌─────────────────────────────────────────────────────────┐ │
│  │                调度配置                                │ │
│  │  ┌─────────────┐  ┌─────────────┐  ┌─────────────┐    │ │
│  │  │ 每周执行    │  │ 每日执行    │  │ 每小时执行   │    │ │
│  │  │ 周一9:00   │  │ 每天9:00   │  │ 每6小时     │    │ │
│  │  └─────────────┘  └─────────────┘  └─────────────┘    │ │
│  └─────────────────────────────────────────────────────────┘ │
└─────────────────────────────────────────────────────────────┘
```

### 调度模式

#### 1. 每周调度（生产模式）
- **执行时间**: 每周一上午9:00
- **适用场景**: 生产环境，定期更新数据
- **启动命令**: `python main.py --mode scheduler --schedule weekly`

#### 2. 每日调度（测试模式）
- **执行时间**: 每天上午9:00
- **适用场景**: 测试环境，频繁更新数据
- **启动命令**: `python main.py --mode scheduler --schedule daily`

#### 3. 每小时调度（开发模式）
- **执行时间**: 每6小时执行一次
- **适用场景**: 开发环境，快速验证功能
- **启动命令**: `python main.py --mode scheduler --schedule hourly`

### 调度器功能特性

#### 1. 智能调度
- **时间管理**: 精确到分钟的时间控制
- **任务队列**: 支持任务排队和优先级
- **错误重试**: 自动重试失败的任务
- **状态跟踪**: 记录每次执行的状态

#### 2. 资源管理
- **内存控制**: 自动释放不需要的资源
- **连接池**: 数据库连接池管理
- **并发控制**: 避免重复执行任务
- **日志记录**: 详细的执行日志

#### 3. 监控告警
- **执行状态**: 实时监控任务执行状态
- **错误告警**: 任务失败时自动告警
- **性能监控**: 监控系统性能指标
- **数据统计**: 统计爬取和总结的数据量

### 启动方式

#### 1. 脚本启动
```bash
# 每周自动爬取
start_scheduler.bat

# 每日自动爬取
start_daily_scheduler.bat
```
bat的windows才能用，MAC就用命令行启动吧

#### 2. 命令行启动
```bash
# 每周调度
python main.py --mode scheduler --schedule weekly

# 每日调度
python main.py --mode scheduler --schedule daily

# 每小时调度
python main.py --mode scheduler --schedule hourly

# 立即执行一次
python main.py --mode run_once
```
这个每日调度和每小时调度是测试自动定时爬取能不能行的时候搞的，顺便一起保留下来了，因为把自动爬取和api模式写成单线程老容易堵塞卡死，所以改成双线程了，或者只启动api模式然后需要的时候手动执行一下爬取（所以加了个run_once）


#### 3. 服务化部署
```bash
# 使用systemd（Linux）
sudo systemctl start policy-scheduler

# 使用Windows服务
sc create "PolicyScheduler" binPath="python main.py --mode scheduler"
```

## 核心模块说明

### 1. 爬虫模块 (crawler.py)
- **功能**: 爬取北京市和广东省政府网站
- **特点**: 
  - 支持关键词过滤
  - 自动去重
  - 错误处理和重试
  - 请求频率控制

### 2. AI总结模块 (ai_summarizer.py)
- **功能**: 调用AI API进行政策总结
- **特点**:
  - 结构化提示词
  - JSON格式输出
  - 错误处理和重试
  - 批量处理

### 3. 数据库模块 (database.py)
- **功能**: 数据存储和管理
- **特点**:
  - SQLite轻量级数据库
  - SQLAlchemy ORM
  - 自动表创建
  - 数据关系管理

### 4. API接口模块 (api.py)
- **功能**: 提供RESTful API
- **特点**:
  - FastAPI框架
  - 自动文档生成
  - CORS支持
  - 错误处理

### 5. 定时任务模块 (scheduler.py)
- **功能**: 定时执行爬取和总结
- **特点**:
  - 可配置执行频率
  - 任务状态跟踪
  - 错误日志记录

## 技术栈

### 后端技术
- **Python 3.8+**: 主要编程语言
- **FastAPI**: Web框架
- **SQLAlchemy**: ORM框架
- **SQLite**: 数据库
- **requests**: HTTP客户端
- **BeautifulSoup**: HTML解析
- **schedule**: 定时任务


### AI集成
- **SiliconFlow API**: AI服务提供商
- **deepseek-chat**: 大语言模型
- **JSON格式**: 结构化输出

## 部署架构

### 开发环境
```
本地开发 → Python虚拟环境 → SQLite数据库 → 本地API服务
```

### 生产环境
```
服务器部署 → 数据库备份 → 定时任务 → 监控告警
```

## 监控和日志

### 1. 系统监控
- 爬取成功率
- API响应时间
- 数据库性能

### 2. 日志记录
- 操作日志
- 错误日志
- 性能日志

