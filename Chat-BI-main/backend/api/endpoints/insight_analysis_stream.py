from fastapi import APIRouter, HTTPException, Depends
from fastapi.responses import StreamingResponse
from pydantic import BaseModel
from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy import select
import json
import logging
import asyncio
import aiohttp
import time

from models.sys_ai_model_config import SysAiModelConfig
from db.session import async_session
from services.conversation_service import save_user_message, save_assistant_message, update_conversation_summary

router = APIRouter()
logger = logging.getLogger(__name__)


async def generate_title_async(conversation_id: int, user_question: str):
    """å¼‚æ­¥ç”Ÿæˆä¼šè¯æ ‡é¢˜"""
    try:
        async with async_session() as db:
            from services.model_cache_service import ModelCacheService
            from models.sys_conversation import SysConversation

            # è·å–ä¼šè¯ä¿¡æ¯
            conv_result = await db.execute(
                select(SysConversation).where(SysConversation.id == conversation_id)
            )
            conversation = conv_result.scalar_one_or_none()

            if not conversation:
                logger.warning(f"ä¼šè¯ {conversation_id} ä¸å­˜åœ¨ï¼Œæ— æ³•ç”Ÿæˆæ ‡é¢˜")
                return

            # å†æ¬¡æ£€æŸ¥æ˜¯å¦éœ€è¦ç”Ÿæˆæ ‡é¢˜
            if conversation.title != "æ–°å¯¹è¯":
                logger.info(f"ä¼šè¯ {conversation_id} å·²æœ‰æ ‡é¢˜ï¼Œè·³è¿‡ç”Ÿæˆ")
                return

            generated_title = None
            
            try:
                # è·å–AIé…ç½®
                model_config = await ModelCacheService.get_user_selected_model(
                    user_id=conversation.user_id,
                    db=db
                )

                if not model_config:
                    logger.warning(f"ç”¨æˆ· {conversation.user_id} æ²¡æœ‰AIé…ç½®ï¼Œä½¿ç”¨ç”¨æˆ·é—®é¢˜çš„å‰50ä¸ªå­—ç¬¦ä½œä¸ºæ ‡é¢˜")
                    # æ²¡æœ‰AIé…ç½®ï¼Œä½¿ç”¨ç”¨æˆ·é—®é¢˜çš„å‰50ä¸ªå­—ç¬¦ä½œä¸ºæ ‡é¢˜
                    generated_title = user_question[:50] + ("..." if len(user_question) > 50 else "")
                else:
                    logger.info(f"ä½¿ç”¨AIæ¨¡å‹ {model_config.get('model_name')} ç”Ÿæˆæ ‡é¢˜")
                    
                    # è°ƒç”¨AIç”Ÿæˆç®€æ´çš„æ ‡é¢˜
                    system_prompt = (
                        "ä½ æ˜¯ä¸€ä¸ªä¼šè¯æ ‡é¢˜ç”ŸæˆåŠ©æ‰‹ã€‚æ ¹æ®ç”¨æˆ·çš„é—®é¢˜ï¼Œç”Ÿæˆä¸€ä¸ªç®€æ´ã€å‡†ç¡®çš„ä¼šè¯æ ‡é¢˜ã€‚\n"
                        "è¦æ±‚ï¼š\n"
                        "1. æ ‡é¢˜é•¿åº¦ä¸è¶…è¿‡30ä¸ªå­—ç¬¦\n"
                        "2. å‡†ç¡®æ¦‚æ‹¬ç”¨æˆ·é—®é¢˜çš„æ ¸å¿ƒå†…å®¹\n"
                        "3. ä½¿ç”¨ä¸­æ–‡\n"
                        "4. ä¸è¦ä½¿ç”¨å¼•å·æˆ–ç‰¹æ®Šç¬¦å·\n"
                        "5. ç›´æ¥è¿”å›æ ‡é¢˜æ–‡æœ¬ï¼Œä¸è¦æœ‰ä»»ä½•å…¶ä»–è¯´æ˜\n\n"
                        f"ç”¨æˆ·é—®é¢˜ï¼š{user_question}\n\n"
                        "è¯·ç”Ÿæˆæ ‡é¢˜ï¼š"
                    )

                    headers = {
                        "Content-Type": "application/json",
                        "Authorization": f"Bearer {model_config.get('api_key', '')}",
                    }

                    data = {
                        "model": model_config.get('model_name', ''),
                        "messages": [{"role": "system", "content": system_prompt}],
                        "temperature": 0.7,
                        "max_tokens": 100,
                    }

                    # å¢åŠ é‡è¯•æœºåˆ¶
                    max_retries = 2
                    for attempt in range(max_retries + 1):
                        try:
                            timeout = aiohttp.ClientTimeout(total=15)  # å¢åŠ è¶…æ—¶æ—¶é—´
                            async with aiohttp.ClientSession(timeout=timeout) as session:
                                async with session.post(
                                    model_config.get('api_url', ''),
                                    json=data,
                                    headers=headers
                                ) as response:
                                    if response.status == 200:
                                        result = await response.json()
                                        # æ£€æŸ¥å“åº”æ ¼å¼
                                        if 'choices' in result and len(result['choices']) > 0:
                                            content = result['choices'][0].get('message', {}).get('content', '')
                                            if content:
                                                generated_title = content.strip()
                                                # å»é™¤å¯èƒ½çš„å¼•å·
                                                generated_title = generated_title.strip('"').strip("'")
                                                # é™åˆ¶é•¿åº¦ï¼ˆæ•°æ®åº“é™åˆ¶200ï¼Œä½†UIæ˜¾ç¤ºé™åˆ¶50ï¼‰
                                                if len(generated_title) > 50:
                                                    generated_title = generated_title[:50] + "..."
                                                logger.info(f"AIæ ‡é¢˜ç”ŸæˆæˆåŠŸ: {generated_title}")
                                                break
                                            else:
                                                logger.warning("AIè¿”å›ç©ºå†…å®¹")
                                        else:
                                            logger.warning("AIè¿”å›æ ¼å¼å¼‚å¸¸")
                                    else:
                                        logger.warning(f"AIæ ‡é¢˜ç”Ÿæˆå¤±è´¥: HTTP {response.status}")
                                        if attempt < max_retries:
                                            logger.info(f"é‡è¯•ç¬¬ {attempt + 1} æ¬¡...")
                                            await asyncio.sleep(1)  # ç­‰å¾…1ç§’åé‡è¯•
                                            
                        except asyncio.TimeoutError:
                            logger.warning(f"AIæ ‡é¢˜ç”Ÿæˆè¶…æ—¶ (å°è¯• {attempt + 1}/{max_retries + 1})")
                            if attempt < max_retries:
                                await asyncio.sleep(1)
                        except Exception as e:
                            logger.warning(f"AIæ ‡é¢˜ç”Ÿæˆè¯·æ±‚å¤±è´¥ (å°è¯• {attempt + 1}/{max_retries + 1}): {e}")
                            if attempt < max_retries:
                                await asyncio.sleep(1)
                    
                    # å¦‚æœAIç”Ÿæˆå¤±è´¥ï¼Œä½¿ç”¨å¤‡ç”¨æ–¹æ¡ˆ
                    if not generated_title:
                        logger.warning("AIæ ‡é¢˜ç”Ÿæˆå®Œå…¨å¤±è´¥ï¼Œä½¿ç”¨ç”¨æˆ·é—®é¢˜ä½œä¸ºæ ‡é¢˜")
                        generated_title = user_question[:50] + ("..." if len(user_question) > 50 else "")
                        
            except Exception as e:
                logger.error(f"æ ‡é¢˜ç”Ÿæˆè¿‡ç¨‹å¼‚å¸¸: {e}")
                generated_title = user_question[:50] + ("..." if len(user_question) > 50 else "")

            # æ›´æ–°ä¼šè¯æ ‡é¢˜
            if generated_title:
                conversation.title = generated_title
                await db.commit()
                logger.info(f"ä¼šè¯ {conversation_id} æ ‡é¢˜å·²è‡ªåŠ¨ç”Ÿæˆ: {generated_title}")
            else:
                logger.error(f"ä¼šè¯ {conversation_id} æ ‡é¢˜ç”Ÿæˆå¤±è´¥ï¼Œä¿æŒåŸæ ‡é¢˜")

    except Exception as e:
        logger.error(f"å¼‚æ­¥ç”Ÿæˆä¼šè¯æ ‡é¢˜å¤±è´¥: {e}")


async def update_summary_async(conversation_id: int, user_question: str, assistant_response: str):
    """å¼‚æ­¥æ›´æ–°ä¼šè¯æ‘˜è¦"""
    try:
        async with async_session() as db:
            from services.model_cache_service import ModelCacheService
            from models.sys_conversation import SysConversation

            # è·å–ä¼šè¯ä¿¡æ¯
            conv_result = await db.execute(
                select(SysConversation).where(SysConversation.id == conversation_id)
            )
            conversation = conv_result.scalar_one_or_none()

            if not conversation:
                logger.warning(f"ä¼šè¯ {conversation_id} ä¸å­˜åœ¨ï¼Œæ— æ³•æ›´æ–°æ‘˜è¦")
                return

            # è·å–AIé…ç½®
            model_config = await ModelCacheService.get_user_selected_model(
                user_id=conversation.user_id,
                db=db
            )

            # æ›´æ–°æ‘˜è¦
            await update_conversation_summary(
                db,
                conversation_id,
                user_question,
                assistant_response,
                model_config=model_config
            )

    except Exception as e:
        logger.error(f"å¼‚æ­¥æ›´æ–°ä¼šè¯æ‘˜è¦å¤±è´¥: {e}")


async def get_db():
    async with async_session() as session:
        yield session


async def get_default_ai_config_for_user(user_id: int, db: AsyncSession):
    """è·å–ç”¨æˆ·çš„é»˜è®¤AIé…ç½®"""
    result = await db.execute(
        select(SysAiModelConfig)
        .where(
            SysAiModelConfig.user_id == user_id,
            SysAiModelConfig.is_default == True,
            SysAiModelConfig.is_active == True
        )
    )
    return result.scalar_one_or_none()


class StreamInsightRequest(BaseModel):
    user_input: str
    data: str  # JSONæ ¼å¼çš„æ•°æ®


@router.post("/insight_analysis_stream")
async def insight_analysis_stream(request: StreamInsightRequest):
    """æµå¼æ´å¯Ÿåˆ†æ"""

    # ç”¨äºæ”¶é›†å®Œæ•´çš„æµå¼è¾“å‡º
    complete_content = []
    conversation_id = None
    start_time = time.time()
    tokens_used = None  # è®°å½•tokenä½¿ç”¨é‡
    prompt_tokens = 0  # æç¤ºè¯tokenæ•°
    completion_tokens = 0  # ç”Ÿæˆtokenæ•°

    async def generate_stream():
        nonlocal complete_content, conversation_id, start_time, tokens_used, prompt_tokens, completion_tokens

        try:
            # è·å–AIé…ç½® (ä½¿ç”¨Redisç¼“å­˜)
            from services.model_cache_service import ModelCacheService

            # å…ˆè§£ædataå­—æ®µ,åˆ¤æ–­æ˜¯å¦ä¸ºæ™®é€šèŠå¤©æ¨¡å¼ï¼ˆå¿…é¡»åœ¨æ•°æ®åº“ä¼šè¯ä¹‹å‰ï¼‰
            # åˆå§‹åŒ–å˜é‡ï¼Œé¿å…åœ¨exceptå—å¤–ä½¿ç”¨æœªå®šä¹‰çš„å˜é‡
            is_chat_mode = False
            is_analysis_mode = False
            data_obj = {}
            
            try:
                data_obj = json.loads(request.data)
                is_chat_mode = data_obj.get('mode') == 'chat'
                is_analysis_mode = data_obj.get('mode') == 'analysis'
                logger.info(f"è§£æè¯·æ±‚æ•°æ®: mode={data_obj.get('mode')}, conversation_id={data_obj.get('conversation_id')}, is_chat_mode={is_chat_mode}, is_analysis_mode={is_analysis_mode}")
            except Exception as e:
                logger.error(f"è§£æè¯·æ±‚æ•°æ®å¤±è´¥: {e}")
                is_chat_mode = False
                is_analysis_mode = False

            async with async_session() as db:
                # åªåœ¨èŠå¤©æ¨¡å¼ä¸‹ä¿å­˜ç”¨æˆ·æ¶ˆæ¯ï¼Œæ´å¯Ÿåˆ†ææ¨¡å¼ä¸ä¿å­˜ç”¨æˆ·æ¶ˆæ¯
                if is_chat_mode:
                    try:
                        # ä¼˜å…ˆä½¿ç”¨ä¼ é€’çš„conversation_idï¼Œå¦‚æœæ²¡æœ‰åˆ™åˆ›å»ºæ–°å¯¹è¯
                        conversation_id = data_obj.get('conversation_id')
                        if conversation_id and conversation_id != 'null' and conversation_id != 'undefined':
                            # ä½¿ç”¨ç°æœ‰å¯¹è¯ï¼Œç›´æ¥ä¿å­˜ç”¨æˆ·æ¶ˆæ¯
                            from services.conversation_service import save_message
                            from models.sys_conversation import MessageRoleEnum
                            user_message = await save_message(
                                db,
                                conversation_id,
                                MessageRoleEnum.USER,
                                request.user_input
                            )
                            logger.info(f"ç”¨æˆ·æ¶ˆæ¯å·²ä¿å­˜åˆ°ç°æœ‰å¯¹è¯: conversation_id={conversation_id}, message_id={user_message.id}")
                        else:
                            # åˆ›å»ºæ–°å¯¹è¯
                            conversation, user_message = await save_user_message(
                                db,
                                request.user_input,
                                user_id=1
                            )
                            conversation_id = conversation.id
                            logger.info(f"ç”¨æˆ·æ¶ˆæ¯å·²ä¿å­˜åˆ°æ–°å¯¹è¯: conversation_id={conversation_id}, message_id={user_message.id}")
                    except Exception as e:
                        logger.warning(f"ä¿å­˜ç”¨æˆ·æ¶ˆæ¯å¤±è´¥(ä¸å½±å“ä¸»æµç¨‹): {e}")
                elif is_analysis_mode:
                    # æ´å¯Ÿåˆ†ææ¨¡å¼ï¼šä»dataä¸­è·å–conversation_idï¼Œä¸ä¿å­˜ç”¨æˆ·æ¶ˆæ¯
                    try:
                        conversation_id = data_obj.get('conversation_id')
                        if not conversation_id:
                            logger.warning("æ´å¯Ÿåˆ†ææ¨¡å¼ç¼ºå°‘conversation_idï¼Œæ— æ³•ä¿å­˜AIå›å¤")
                    except Exception as e:
                        logger.warning(f"è·å–conversation_idå¤±è´¥: {e}")
                else:
                    # é»˜è®¤æ¨¡å¼ï¼šä¿å­˜ç”¨æˆ·æ¶ˆæ¯ï¼ˆå‘åå…¼å®¹ï¼‰
                    try:
                        conversation, user_message = await save_user_message(
                            db,
                            request.user_input,
                            user_id=1
                        )
                        conversation_id = conversation.id
                        logger.info(f"ç”¨æˆ·æ¶ˆæ¯å·²ä¿å­˜(é»˜è®¤æ¨¡å¼): conversation_id={conversation_id}, message_id={user_message.id}")
                    except Exception as e:
                        logger.warning(f"ä¿å­˜ç”¨æˆ·æ¶ˆæ¯å¤±è´¥(ä¸å½±å“ä¸»æµç¨‹): {e}")

                model_config = await ModelCacheService.get_user_selected_model(
                    user_id=1,  # æš‚æ—¶ä½¿ç”¨å›ºå®šç”¨æˆ·ID
                    db=db
                )

                if not model_config:
                    yield f"data: {json.dumps({'error': 'æœªæ‰¾åˆ°AIé…ç½®ï¼Œè¯·å…ˆåœ¨è®¾ç½®ä¸­é…ç½®AIæ¨¡å‹'}, ensure_ascii=False)}\n\n"
                    return

                # è½¬æ¢ä¸ºAPIè°ƒç”¨æ ¼å¼
                config = {
                    'apiKey': model_config.get('api_key', ''),
                    'baseUrl': model_config.get('api_url', ''),
                    'model': model_config.get('model_name', ''),
                    'temperature': model_config.get('temperature', 0.7),
                    'maxTokens': model_config.get('max_tokens', 2000)
                }

                # å¦‚æœæ˜¯èŠå¤©æ¨¡å¼ï¼Œè¿›è¡Œæ„å›¾è¯†åˆ«ï¼ˆä»…ç”¨äºæ—¥å¿—è®°å½•ï¼Œä¸å½±å“å¤„ç†æµç¨‹ï¼‰ï¼Œå¹¶æ„å»ºä¸Šä¸‹æ–‡
                chat_messages = []
                if is_chat_mode:
                    from services.intent_router import classify_intent, IntentType
                    from sqlalchemy import select
                    from models.sys_conversation import SysConversation, SysConversationMessage
                    
                    try:
                        intent_result = await classify_intent(request.user_input)
                        logger.info(f"èŠå¤©æ¨¡å¼æ„å›¾è¯†åˆ«: {intent_result['intent']} (ç½®ä¿¡åº¦: {intent_result['confidence']})")
                        # æ³¨æ„ï¼šå³ä½¿æ˜¯é—²èŠï¼Œä¹Ÿç»§ç»­èµ°AIå¯¹è¯æµç¨‹ï¼Œè®©AIæ¨¡å‹ç”ŸæˆåŠ¨æ€å›å¤
                    except Exception as e:
                        logger.warning(f"æ„å›¾è¯†åˆ«å¤±è´¥ï¼Œç»§ç»­æ­£å¸¸å¤„ç†: {e}")

                    # æ„å»ºè¿‘æœŸå¯¹è¯çª—å£ + ä¼šè¯æ‘˜è¦
                    try:
                        if conversation_id:
                            # è¯»å–ä¼šè¯æ‘˜è¦
                            conv_result = await db.execute(
                                select(SysConversation).where(SysConversation.id == conversation_id)
                            )
                            conv = conv_result.scalar_one_or_none()
                            summary_text = (conv.summary or '').strip() if conv else ''

                            # è¯»å–æœ€è¿‘Næ¡æ¶ˆæ¯ï¼ˆä¸åŒ…å«å½“å‰è½®ï¼‰
                            msg_result = await db.execute(
                                select(SysConversationMessage)
                                .where(SysConversationMessage.conversation_id == conversation_id)
                                .order_by(SysConversationMessage.created_at.desc())
                                .limit(8)
                            )
                            recent_msgs = list(reversed(msg_result.scalars().all()))

                            # å°†æ‘˜è¦ä½œä¸ºsystemå‰ç½®ï¼ˆå¦‚æœ‰ï¼‰
                            if summary_text:
                                chat_messages.append({
                                    'role': 'system',
                                    'content': f"ä¼šè¯æ‘˜è¦ï¼š{summary_text}"
                                })

                            # æ³¨å…¥æœ€è¿‘æ¶ˆæ¯ï¼ˆä»…ä¿ç•™æ–‡æœ¬å†…å®¹ï¼›å¦‚å«å›¾è¡¨ï¼Œé™„ä¸Šç®€è¦è¯´æ˜ï¼‰
                            for m in recent_msgs:
                                role = 'user' if m.role.value.lower() == 'user' else 'assistant'
                                content = m.content or ''
                                # å¦‚æœæ˜¯å›¾è¡¨æ¶ˆæ¯ï¼Œè¡¥å……ä¸€è¡Œä¸Šä¸‹æ–‡æ‘˜è¦
                                if (not content) and m.chart_data:
                                    try:
                                        import json as _json
                                        _cd = _json.loads(m.chart_data)
                                        cols = []
                                        if isinstance(_cd, dict) and 'data' in _cd and isinstance(_cd['data'], list) and _cd['data']:
                                            cols = list(_cd['data'][0].keys())[:6]
                                        content = f"[ä¸Šè½®å›¾è¡¨ä¸Šä¸‹æ–‡] åˆ—: {', '.join(cols)}"
                                    except Exception:
                                        content = "[ä¸Šè½®å›¾è¡¨ä¸Šä¸‹æ–‡]"
                                if content:
                                    chat_messages.append({'role': role, 'content': content})

                    except Exception as e:
                        logger.warning(f"æ„å»ºå¯¹è¯ä¸Šä¸‹æ–‡å¤±è´¥: {e}")

            # åŠ¨æ€è·å–å½“å‰æ—¶é—´ä¿¡æ¯
            from datetime import datetime
            import pytz

            # è·å–ä¸­å›½æ—¶åŒºçš„å½“å‰æ—¶é—´
            china_tz = pytz.timezone('Asia/Shanghai')
            current_time = datetime.now(china_tz)
            current_date = current_time.strftime('%Y-%m-%d')
            current_year = current_time.year
            current_month = current_time.month

            # æ ¹æ®æ¨¡å¼æ„å»ºä¸åŒçš„æç¤ºè¯/æ¶ˆæ¯
            if is_chat_mode:
                # æ™®é€šèŠå¤©æ¨¡å¼ï¼šé‡‡ç”¨æ··åˆæ–¹æ¡ˆï¼ˆè¿‘æœŸçª—å£ + æ‘˜è¦ + æœ¬è½®é—®é¢˜ï¼‰
                system_prompt = (
                    "ä½ æ˜¯ChatBIåŠ©æ‰‹ï¼Œä¸€ä¸ªä¸“ä¸šçš„å•†ä¸šæ™ºèƒ½åŠ©æ‰‹ã€‚\n\n"
                    f"å½“å‰æ—¶é—´ï¼š{current_date}\n\n"
                    "ä½ çš„èŒè´£ï¼š\n"
                    "1. å‹å¥½ã€ä¸“ä¸šåœ°å›ç­”ç”¨æˆ·çš„å„ç§é—®é¢˜ï¼ŒåŒ…æ‹¬é—²èŠã€æ•°æ®åˆ†æå’¨è¯¢ç­‰\n"
                    "2. å¦‚æœç”¨æˆ·è¯¢é—®æ•°æ®åˆ†æç›¸å…³é—®é¢˜ï¼Œå¼•å¯¼ä»–ä»¬ä¸Šä¼ æ•°æ®é›†æˆ–é€‰æ‹©å·²æœ‰æ•°æ®é›†\n"
                    "3. å¦‚æœç”¨æˆ·è¯¢é—®ä¸æ•°æ®åˆ†ææ— å…³çš„é—®é¢˜ï¼ˆå¦‚å¤©æ°”ã€æ—¥å¸¸èŠå¤©ç­‰ï¼‰ï¼Œè‡ªç„¶å‹å¥½åœ°å›ç­”\n"
                    "4. ç®€æ´æ˜äº†åœ°è¡¨è¾¾ï¼Œä½¿ç”¨Markdownæ ¼å¼\n\n"
                    "å›ç­”éœ€åŸºäºä¸‹æ–¹å¯¹è¯ä¸Šä¸‹æ–‡ï¼ˆè‹¥æœ‰ï¼‰ä¸å½“å‰é—®é¢˜ã€‚"
                )
                # ç»„è£…æ¶ˆæ¯ï¼šsystem + ä¸Šæ–‡çª—å£ + å½“å‰é—®é¢˜
                messages_payload = [{'role': 'system', 'content': system_prompt}]
                if chat_messages:
                    messages_payload.extend(chat_messages)
                # å½“å‰é—®é¢˜ä½œä¸ºæœ€åä¸€æ¡ç”¨æˆ·æ¶ˆæ¯
                messages_payload.append({'role': 'user', 'content': request.user_input})
            else:
                # æ•°æ®æ´å¯Ÿåˆ†ææ¨¡å¼
                system_prompt = (
                    "åŸºäºç”¨æˆ·çš„é—®é¢˜å’ŒæŸ¥è¯¢ç»“æœï¼Œç”Ÿæˆæ·±å…¥çš„æ´å¯Ÿåˆ†æã€‚åˆ†æåº”è¯¥ç®€æ´æ˜äº†ï¼Œå¹¶æä¾›ä»æ•°æ®ä¸­å¾—å‡ºçš„æœ‰æ„ä¹‰çš„è§è§£ã€‚\n\n"
                    f"å½“å‰æ—¶é—´ä¸Šä¸‹æ–‡ï¼šä»Šå¤©æ˜¯{current_date}ï¼Œå½“å‰å¹´ä»½æ˜¯{current_year}å¹´{current_month}æœˆ\n"
                    f"æ•°æ®æ—¶é—´èŒƒå›´ï¼š2024å¹´6æœˆè‡³12æœˆ\n\n"
                    f"ç”¨æˆ·é—®é¢˜ï¼š{request.user_input}\n\n"
                    f"æŸ¥è¯¢ç»“æœï¼š\n{request.data}\n\n"
                    "è¯·æŒ‰ç…§ä»¥ä¸‹Markdownæ ¼å¼è¿”å›åˆ†æç»“æœï¼š\n\n"
                    "## ğŸ“Š æ•°æ®æ´å¯Ÿåˆ†æ\n\n"
                    "### ğŸ” å…³é”®å‘ç°\n"
                    "- **æ ¸å¿ƒæŒ‡æ ‡**ï¼š[æè¿°ä¸»è¦æ•°æ®æŒ‡æ ‡]\n"
                    "- **æ•°æ®è¶‹åŠ¿**ï¼š[æè¿°æ•°æ®å˜åŒ–è¶‹åŠ¿]\n"
                    "- **å¯¹æ¯”åˆ†æ**ï¼š[å¦‚æœ‰å¯¹æ¯”æ•°æ®ï¼Œè¿›è¡Œåˆ†æ]\n\n"
                    "### ğŸ’¡ æ·±åº¦è§£è¯»\n"
                    "[è¯¦ç»†åˆ†ææ•°æ®èƒŒåçš„åŸå› å’Œæ„ä¹‰]\n\n"
                    "### ğŸ“ˆ ä¸šåŠ¡å¯ç¤º\n"
                    "1. **çŸ­æœŸå½±å“**ï¼š[åˆ†æå¯¹å½“å‰çš„å½±å“]\n"
                    "2. **é•¿æœŸè¶‹åŠ¿**ï¼š[é¢„æµ‹æœªæ¥å¯èƒ½çš„å‘å±•]\n"
                    "3. **è¡ŒåŠ¨å»ºè®®**ï¼š[åŸºäºæ•°æ®æä¾›çš„å»ºè®®]\n\n"
                    "### ğŸ¯ å…³æ³¨è¦ç‚¹\n"
                    "> [é‡ç‚¹æé†’æˆ–éœ€è¦ç‰¹åˆ«å…³æ³¨çš„æ•°æ®ç‚¹]\n\n"
                    "> å¦‚æœæ²¡æœ‰è·å–å›¾è¡¨æ•°æ®ä¸åšåˆ†æï¼Œç›´æ¥å‘Šè¯‰å®¢æˆ·ç¼ºå°‘æ•°æ®ï¼Œä¸è¦åšä»»ä½•åˆ†æ\n\n"
                    "è¯·ç¡®ä¿åˆ†æå†…å®¹å‡†ç¡®ã€æœ‰è§åœ°ï¼Œå¹¶ä¸ç”¨æˆ·çš„é—®é¢˜ç´§å¯†ç›¸å…³ã€‚ä½¿ç”¨ä¸­æ–‡å›ç­”ã€‚ç›´æ¥è¿”å›Markdownæ ¼å¼çš„åˆ†æå†…å®¹ï¼Œä¸è¦ä½¿ç”¨ä»£ç å—åŒ…è£¹ã€‚"
                )

            headers = {
                "Content-Type": "application/json",
                "Authorization": f"Bearer {config['apiKey']}",
            }

            # é€‚é…ï¼šèŠå¤©æ¨¡å¼ä½¿ç”¨messages_payloadï¼›æ´å¯Ÿæ¨¡å¼ä»ä½¿ç”¨å•system
            if is_chat_mode:
                data = {
                    "model": config["model"],
                    "messages": messages_payload,
                    "temperature": config.get("temperature", 0.7),
                    "max_tokens": config.get("maxTokens", 2000),
                    "stream": True,
                }
            else:
                data = {
                    "model": config["model"],
                    "messages": [{"role": "system", "content": system_prompt}],
                    "temperature": config.get("temperature", 0.7),
                    "max_tokens": config.get("maxTokens", 2000),
                    "stream": True,
                }

            timeout = aiohttp.ClientTimeout(total=60)
            async with aiohttp.ClientSession(timeout=timeout) as session:
                async with session.post(
                    config["baseUrl"], json=data, headers=headers
                ) as response:
                    if response.status != 200:
                        error_text = await response.text()
                        yield f"data: {json.dumps({'error': f'AIè°ƒç”¨å¤±è´¥: {error_text}'})}\n\n"
                        return

                    # å¤„ç†æµå¼å“åº”
                    async for line in response.content:
                        if line:
                            line_text = line.decode("utf-8").strip()
                            if line_text.startswith("data: "):
                                data_part = line_text[6:]  # å»æ‰'data: 'å‰ç¼€

                                if data_part == "[DONE]":
                                    yield f"data: {json.dumps({'done': True})}\n\n"
                                    break

                                try:
                                    chunk_data = json.loads(data_part)
                                    if (
                                        "choices" in chunk_data
                                        and len(chunk_data["choices"]) > 0
                                    ):
                                        choice = chunk_data["choices"][0]
                                        if (
                                            "delta" in choice
                                            and "content" in choice["delta"]
                                        ):
                                            content = choice["delta"]["content"]
                                            if content:
                                                # æ”¶é›†å®Œæ•´å†…å®¹
                                                complete_content.append(content)
                                                yield f"data: {json.dumps({'content': content})}\n\n"

                                    # æå–tokenä½¿ç”¨é‡ï¼ˆæ”¯æŒå¤šç§APIå“åº”æ ¼å¼ï¼‰
                                    if "usage" in chunk_data:
                                        usage_data = chunk_data["usage"]
                                        # ä¼˜å…ˆè®°å½•è¯¦ç»†çš„tokenç»Ÿè®¡
                                        prompt_tokens = usage_data.get("prompt_tokens", 0)
                                        completion_tokens = usage_data.get("completion_tokens", 0)
                                        tokens_used = usage_data.get("total_tokens") or (prompt_tokens + completion_tokens)
                                        logger.info(f"æ”¶åˆ°tokenä½¿ç”¨é‡: æç¤º={prompt_tokens}, ç”Ÿæˆ={completion_tokens}, æ€»è®¡={tokens_used}")
                                except json.JSONDecodeError:
                                    continue
                                except Exception as e:
                                    logger.error(f"å¤„ç†æµå¼æ•°æ®å‡ºé”™: {e}")
                                    continue

            # æµå¼è¾“å‡ºå®Œæˆå,ä¿å­˜åˆ°æ•°æ®åº“
            if conversation_id and complete_content:
                try:
                    async with async_session() as db:
                        full_content = ''.join(complete_content)
                        response_time = int((time.time() - start_time) * 1000)
                        await save_assistant_message(
                            db,
                            conversation_id,
                            content=full_content,
                            response_time=response_time,
                            tokens_used=tokens_used
                        )
                        logger.info(f"AIæµå¼å›å¤å·²ä¿å­˜: conversation_id={conversation_id}, å†…å®¹é•¿åº¦={len(full_content)}, tokensä½¿ç”¨é‡={tokens_used}")

                        # æ£€æŸ¥æ˜¯å¦éœ€è¦ç”Ÿæˆä¼šè¯æ ‡é¢˜ï¼ˆä»…ç¬¬ä¸€è½®å¯¹è¯ï¼š1æ¡ç”¨æˆ·æ¶ˆæ¯+1æ¡AIæ¶ˆæ¯=2æ¡ï¼‰
                        from models.sys_conversation import SysConversation
                        conv_result = await db.execute(
                            select(SysConversation).where(SysConversation.id == conversation_id)
                        )
                        conversation = conv_result.scalar_one_or_none()

                        if conversation and conversation.message_count == 2 and conversation.title == "æ–°å¯¹è¯":
                            # å¼‚æ­¥ç”Ÿæˆæ ‡é¢˜ï¼ˆä¸é˜»å¡æµå¼è¾“å‡ºï¼‰
                            asyncio.create_task(generate_title_async(conversation_id, request.user_input))
                            logger.info(f"å·²è§¦å‘ä¼šè¯æ ‡é¢˜ç”Ÿæˆä»»åŠ¡: conversation_id={conversation_id}")

                        # å¼‚æ­¥æ›´æ–°ä¼šè¯æ‘˜è¦ï¼ˆæ¯è½®å¯¹è¯éƒ½æ›´æ–°ï¼‰
                        asyncio.create_task(update_summary_async(conversation_id, request.user_input, full_content))
                        logger.info(f"å·²è§¦å‘ä¼šè¯æ‘˜è¦æ›´æ–°ä»»åŠ¡: conversation_id={conversation_id}")

                except Exception as e:
                    logger.error(f"ä¿å­˜AIæµå¼å›å¤å¤±è´¥: {e}")

        except asyncio.TimeoutError:
            yield f"data: {json.dumps({'error': 'è¯·æ±‚è¶…æ—¶'})}\n\n"
        except Exception as e:
            logger.error(f"æµå¼æ´å¯Ÿåˆ†æå‡ºé”™: {e}")
            yield f"data: {json.dumps({'error': f'åˆ†æå¤±è´¥: {str(e)}'})}\n\n"

    return StreamingResponse(
        generate_stream(),
        media_type="text/plain",
        headers={
            "Cache-Control": "no-cache",
            "Connection": "keep-alive",
            "Access-Control-Allow-Origin": "*",
        },
    )


@router.get("/insight_analysis_stream/{user_input}")
async def insight_analysis_stream_get(user_input: str):
    """é€šè¿‡GETæ–¹å¼è·å–æµå¼æ´å¯Ÿåˆ†æ"""

    async def generate_stream():
        try:
            # ä»Redisè·å–ç›¸å…³æ•°æ®
            from api.dependencies.dependencies import redis_client

            data_key = f"chart_data:{user_input}"
            data_json = await redis_client.get(data_key)

            if not data_json:
                yield f"data: {json.dumps({'error': 'æœªæ‰¾åˆ°ç›¸å…³æ•°æ®'})}\n\n"
                return

            # åˆ›å»ºè¯·æ±‚å¯¹è±¡
            request = StreamInsightRequest(user_input=user_input, data=data_json)

            # è°ƒç”¨æµå¼åˆ†æ
            async for chunk in insight_analysis_stream(request).body_iterator:
                yield chunk

        except Exception as e:
            logger.error(f"GETæµå¼æ´å¯Ÿåˆ†æå‡ºé”™: {e}")
            yield f"data: {json.dumps({'error': f'åˆ†æå¤±è´¥: {str(e)}'})}\n\n"

    return StreamingResponse(
        generate_stream(),
        media_type="text/plain",
        headers={
            "Cache-Control": "no-cache",
            "Connection": "keep-alive",
            "Access-Control-Allow-Origin": "*",
        },
    )
