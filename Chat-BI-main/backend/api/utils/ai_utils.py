import os
import json
import logging
import requests
from urllib3.util.retry import Retry
from requests.adapters import HTTPAdapter
from dotenv import load_dotenv
import asyncio  # æ·»åŠ  asyncio æ¨¡å—
import aiohttp

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

# ä»ç¯å¢ƒå˜é‡ä¸­è·å–API URL
api_url_14b_chat = os.getenv("API_URL_14B_CHAT")
api_url_14b_generate = os.getenv("API_URL_14B_GENERATE")
api_url_72b_chat = os.getenv("API_URL_72B_CHAT")

# åˆå§‹åŒ–sessionå¯¹è±¡å¹¶é…ç½®é‡è¯•æœºåˆ¶
session = requests.Session()
retries = Retry(total=5, backoff_factor=1, status_forcelist=[500, 502, 503, 504])
session.mount("http://", HTTPAdapter(max_retries=retries))
session.mount("https://", HTTPAdapter(max_retries=retries))

# ä½¿ç”¨æ¨¡å‹é€‰æ‹©
# å®šä¹‰æ¨¡å‹ç±»å‹å˜é‡
model_type = "72B-chat"  # å¯ä»¥æ˜¯ "14B-chat", "14B-generate", "72B-chat"

# å®šä¹‰æ¨¡å‹é…ç½®æ˜ å°„
model_config = {
    "14B-chat": {
        "api_url": api_url_14b_chat,
        "model": "qwen2.5:14b",
        "call_function": "call_qwen_chat_14B_api",
    },
    "14B-generate": {
        "api_url": api_url_14b_generate,
        "model": "qwen2.5:14b",
        "call_function": "call_qwen_generate_14B_api",
    },
    "72B-chat": {
        "api_url": api_url_72b_chat,
        "model": "/root/.cache/modelscope",
        "call_function": "call_qwen_chat_72B_api",
    },
}


def make_api_request(api_url, headers, data):
    try:
        # å¢åŠ è¶…æ—¶æ—¶é—´åˆ°180ç§’
        response = session.post(
            api_url, headers=headers, data=json.dumps(data), timeout=180
        )
        response.raise_for_status()
        if response.text.strip():
            return response.json()
        else:
            logging.error("APIå“åº”ä¸ºç©º")
            return None
    except requests.exceptions.ConnectionError as e:
        logging.error(f"è¿æ¥é”™è¯¯: {e}")
        return None
    except requests.exceptions.Timeout as e:
        logging.error(f"è¯·æ±‚è¶…æ—¶: {e}")
        return None
    except requests.exceptions.RequestException as e:
        logging.error(f"HTTPè¯·æ±‚é”™è¯¯: {e}")
        return None
    except json.JSONDecodeError as e:
        logging.error(f"JSONè§£æé”™è¯¯: {e}")
        return None
    except Exception as e:
        logging.error(f"æœªçŸ¥é”™è¯¯: {e}")
        return None


def call_qwen_chat_14B_api(api_url, model, system_prompt, user_input):
    headers = {"Content-Type": "application/json"}
    data = {
        "model": model,
        "messages": [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_input},
        ],
        "temperature": 0.5,
        "top_p": 1,
        "repetition_penalty": 1.05,
        "max_tokens": 4000,
        "stream": False,
    }
    result = make_api_request(api_url, headers, data)
    if result and "message" in result and "content" in result["message"]:
        return result["message"]["content"]
    else:
        logging.error("APIå“åº”ä¸­æ²¡æœ‰é¢„æœŸçš„'message'æˆ–'content'å­—æ®µ")
        return None


def call_qwen_generate_14B_api(api_url, model, system_prompt):
    headers = {"Content-Type": "application/json"}
    data = {
        "model": model,
        "prompt": system_prompt,
        "stream": False,
    }
    result = make_api_request(api_url, headers, data)
    if result and "response" in result:
        return result["response"]
    else:
        logging.error("APIå“åº”ä¸­æ²¡æœ‰é¢„æœŸçš„'response'å­—æ®µ")
        return None


def call_qwen_chat_72B_api(api_url, model, system_prompt, user_input=None):
    headers = {"Content-Type": "application/json"}
    messages = [{"role": "system", "content": system_prompt}]
    if user_input:
        messages.append({"role": "user", "content": user_input})

    data = {
        "model": model,
        "messages": messages,
        "temperature": 0.5,
        "top_p": 1,
        "repetition_penalty": 1.05,
        "stream": False,
    }
    result = make_api_request(api_url, headers, data)
    if result and "choices" in result and len(result["choices"]) > 0:
        message = result["choices"][0]["message"]
        if "content" in message:
            return message["content"]
        else:
            logging.error("APIå“åº”ä¸­æ²¡æœ‰é¢„æœŸçš„'content'å­—æ®µ")
            return None
    else:
        logging.error("APIå“åº”ä¸­æ²¡æœ‰é¢„æœŸçš„'choices'å­—æ®µæˆ–'choices'ä¸ºç©º")
        return None


def call_qwen_model(model_type, system_prompt, user_input=None):
    config = model_config.get(model_type)
    if not config:
        logging.error("æœªçŸ¥çš„æ¨¡å‹ç±»å‹")
        return None

    api_url = config["api_url"]
    model = config["model"]
    call_function = config["call_function"]

    if call_function == "call_qwen_chat_14B_api":
        return call_qwen_chat_14B_api(api_url, model, system_prompt, user_input)
    elif call_function == "call_qwen_generate_14B_api":
        return call_qwen_generate_14B_api(api_url, model, system_prompt)
    elif call_function == "call_qwen_chat_72B_api":
        return call_qwen_chat_72B_api(api_url, model, system_prompt, user_input)
    else:
        logging.error("æœªçŸ¥çš„è°ƒç”¨å‡½æ•°")
        return None


async def get_configured_ai_model(user_id: int = 1):
    """
    è·å–é…ç½®çš„AIæ¨¡å‹

    ä¼˜å…ˆä»Redisè·å–ç”¨æˆ·é€‰æ‹©çš„æ¨¡å‹é…ç½®
    å¦‚æœRedisä¸­æ²¡æœ‰,åˆ™ä»æ•°æ®åº“è·å–é»˜è®¤é…ç½®

    Args:
        user_id: ç”¨æˆ·ID,é»˜è®¤ä¸º1

    Returns:
        æ¨¡å‹é…ç½®å­—å…¸,åŒ…å«apiKey, baseUrl, modelç­‰ä¿¡æ¯
    """
    try:
        from sqlalchemy.ext.asyncio import AsyncSession
        from services.model_cache_service import ModelCacheService
        from db.session import async_session

        async with async_session() as db:
            # ä»Redis/æ•°æ®åº“è·å–ç”¨æˆ·é€‰æ‹©çš„æ¨¡å‹é…ç½®
            model_config = await ModelCacheService.get_user_selected_model(
                user_id=user_id,
                db=db
            )

            if model_config:
                return {
                    'apiKey': model_config.get('api_key', ''),
                    'baseUrl': model_config.get('api_url', ''),
                    'model': model_config.get('model_name', ''),
                    'temperature': model_config.get('temperature', 0.7),
                    'maxTokens': model_config.get('max_tokens', 2000)
                }

            logging.warning(f"ç”¨æˆ·{user_id}æ²¡æœ‰å¯ç”¨çš„AIæ¨¡å‹é…ç½®")
            return None
    except Exception as e:
        logging.error(f"è·å–AIé…ç½®å¤±è´¥: {e}")
        return None

async def call_configured_ai_model(system_prompt, user_input=None, user_id: int = 1, return_usage: bool = False):
    """
    è°ƒç”¨é…ç½®çš„AIæ¨¡å‹

    Args:
        system_prompt: ç³»ç»Ÿæç¤ºè¯
        user_input: ç”¨æˆ·è¾“å…¥(å¯é€‰)
        user_id: ç”¨æˆ·ID,ç”¨äºè·å–ç”¨æˆ·é€‰æ‹©çš„æ¨¡å‹é…ç½®
        return_usage: æ˜¯å¦è¿”å›tokenä½¿ç”¨é‡ä¿¡æ¯

    Returns:
        å¦‚æœreturn_usage=False: AIæ¨¡å‹çš„å“åº”å†…å®¹
        å¦‚æœreturn_usage=True: (å“åº”å†…å®¹, tokenä½¿ç”¨é‡å­—å…¸)
    """
    config = await get_configured_ai_model(user_id=user_id)

    if config:
        # ä½¿ç”¨é…ç½®çš„æ¨¡å‹
        try:
            headers = {
                "Content-Type": "application/json",
                "Authorization": f"Bearer {config['apiKey']}"
            }

            messages = [{"role": "system", "content": system_prompt}]
            if user_input:
                messages.append({"role": "user", "content": user_input})

            data = {
                "model": config['model'],
                "messages": messages,
                "temperature": config.get('temperature', 0.7),
                "max_tokens": config.get('maxTokens', 2000)
            }

            timeout = aiohttp.ClientTimeout(total=30)
            async with aiohttp.ClientSession(timeout=timeout) as session:
                async with session.post(config['baseUrl'], json=data, headers=headers) as response:
                    if response.status == 200:
                        result = await response.json()
                        if 'choices' in result and len(result['choices']) > 0:
                            content = result['choices'][0]['message']['content']

                            # æå–tokenä½¿ç”¨é‡
                            if return_usage:
                                usage = result.get('usage', {})
                                token_info = {
                                    'prompt_tokens': usage.get('prompt_tokens', 0),
                                    'completion_tokens': usage.get('completion_tokens', 0),
                                    'total_tokens': usage.get('total_tokens', 0)
                                }
                                return content, token_info
                            else:
                                return content
                    else:
                        error_text = await response.text()
                        logging.error(f"é…ç½®çš„AIè°ƒç”¨å¤±è´¥: HTTP {response.status}: {error_text}")

        except Exception as e:
            logging.error(f"è°ƒç”¨é…ç½®çš„AIæ¨¡å‹å¤±è´¥: {e}")

    # å¦‚æœé…ç½®æ¨¡å‹å¤±è´¥ï¼Œå›é€€åˆ°åŸæœ‰æ¨¡å‹
    logging.info("å›é€€åˆ°åŸæœ‰AIæ¨¡å‹")
    content = call_qwen_model(model_type, system_prompt, user_input)

    if return_usage:
        # å›é€€æ¨¡å‹æ— æ³•è·å–tokenä½¿ç”¨é‡
        return content, {'prompt_tokens': 0, 'completion_tokens': 0, 'total_tokens': 0}
    else:
        return content

async def analyze_user_intent_and_generate_sql(user_input, retry_count=3, user_id: int = 1):
    """
    åˆ†æç”¨æˆ·æ„å›¾å¹¶ç”ŸæˆSQLæŸ¥è¯¢

    Args:
        user_input: ç”¨æˆ·è¾“å…¥
        retry_count: é‡è¯•æ¬¡æ•°
        user_id: ç”¨æˆ·ID,ç”¨äºè·å–ç”¨æˆ·é€‰æ‹©çš„æ¨¡å‹é…ç½®

    Returns:
        ç”Ÿæˆçš„SQLæŸ¥è¯¢è¯­å¥
    """
    # åŠ¨æ€è·å–å½“å‰æ—¶é—´ä¿¡æ¯
    from datetime import datetime
    import pytz

    # è·å–ä¸­å›½æ—¶åŒºçš„å½“å‰æ—¶é—´
    china_tz = pytz.timezone('Asia/Shanghai')
    current_time = datetime.now(china_tz)
    current_year = current_time.year
    current_month = current_time.month
    current_date = current_time.strftime('%Y-%m-%d')

    # ä»ç¯å¢ƒå˜é‡è·å–æ•°æ®åº“è¡¨ç»“æ„
    database_schema = os.getenv("DATABASE_SCHEMA", "")

    system_prompt = (
        "Analyze the user input and generate the corresponding SQL query based on the existing database table clause. "
        f"CURRENT TIME CONTEXT: Today is {current_date}, current year is {current_year}, current month is {current_month}. "
        "IMPORTANT: The data in the database spans from June 2024 to December 2024. "
        "When users mention months without specifying year (like '8æœˆ', '9æœˆ', 'August', 'September'), "
        f"intelligently determine the year based on context - if they're asking about recent months and it's {current_year}, "
        f"they likely mean {current_year} if the month has data, otherwise assume 2024. "
        "Always consider data availability when choosing the year. "
        f"My database build statement:\n\n{database_schema}\n"
        "The SQL query must be formatted in Markdown as follows:\n\n"
        "```sql\n"
        "SELECT * FROM table_name;\n"
        "```\n\n"
        f"TIME INTELLIGENCE RULES:\n"
        f"1. Current date: {current_date}\n"
        f"2. Available data range: June 2024 - December 2024\n"
        f"3. When user asks about months without year, choose the most logical year based on data availability\n"
        f"4. For historical analysis, prefer 2024 data when available\n"
        f"5. Always validate that your chosen date range has data in the database"
    )

    for attempt in range(retry_count):
        try:
            ai_response = await call_configured_ai_model(system_prompt, user_input, user_id=user_id)

            if ai_response:
                sql_start = ai_response.find("```sql\n") + len("```sql\n")
                sql_end = ai_response.find("\n```", sql_start)
                sql_query = ai_response[sql_start:sql_end].strip()

                if sql_query:
                    return sql_query
                else:
                    logging.warning(
                        f"ç¬¬ {attempt + 1} æ¬¡å°è¯•æœªèƒ½ä»AIçš„å›å¤ä¸­æå–SQLè¯­å¥"
                    )
            else:
                logging.warning(f"ç¬¬ {attempt + 1} æ¬¡å°è¯•AIæœªèƒ½ç”Ÿæˆæœ‰æ•ˆçš„å›å¤")
        except Exception as e:
            logging.error(f"ç¬¬ {attempt + 1} æ¬¡å°è¯•å‘ç”Ÿé”™è¯¯: {e}")

    # å¦‚æœæ‰€æœ‰å°è¯•éƒ½å¤±è´¥ï¼Œè¿”å›ä¸€ä¸ªé»˜è®¤çš„SQLæŸ¥è¯¢
    logging.error("å¤šæ¬¡å°è¯•åä»æœªèƒ½ç”ŸæˆSQLè¯­å¥ï¼Œè¿”å›é»˜è®¤æŸ¥è¯¢")
    if "é”€å”®" in user_input or "sales" in user_input.lower():
        return "SELECT sale_date, product_name, amount, quantity FROM sales ORDER BY sale_date DESC LIMIT 10"
    elif "è½¦æµ" in user_input or "äººæµé‡" in user_input:
        return "SELECT statistics_date, all_count, in_count, out_count FROM pl_mobile_people_flow_data ORDER BY statistics_date DESC LIMIT 10"
    elif "äººå£" in user_input:
        return "SELECT date_time, num FROM pl_pop_trend_of_end_year ORDER BY date_time DESC LIMIT 10"
    else:
        # é»˜è®¤è¿”å›salesè¡¨æ•°æ®
        return "SELECT sale_date, product_name, amount, quantity FROM sales ORDER BY sale_date DESC LIMIT 10"


async def refine_data_with_ai(user_input, df, user_id: int = 1):
    """
    ä½¿ç”¨AIç²¾ç‚¼æ•°æ®,ç¡®å®šXè½´å’ŒYè½´

    Args:
        user_input: ç”¨æˆ·è¾“å…¥
        df: æŸ¥è¯¢ç»“æœDataFrame
        user_id: ç”¨æˆ·ID,ç”¨äºè·å–ç”¨æˆ·é€‰æ‹©çš„æ¨¡å‹é…ç½®

    Returns:
        ç²¾ç‚¼åçš„æ•°æ®é…ç½®
    """
    system_prompt = (
        "Based on the user's question and the query result, determine the appropriate columns for the X-axis and Y-axis, "
        "as well as the scale and unit for displaying the data. The column names, scale, and unit should be returned in JSON format using markdown.\n\n"
        "User's question: {user_input}\n\n"
        "Query result:\n\n"
        f"{df.to_json(orient='records')}\n\n"
        "The JSON format should be as follows:\n\n"
        "```json\n"
        "{\n"
        '  "x_axis": "column_name",\n'
        '  "y_axes": ["column_name1", "column_name2", ...],\n'
        '  "scale": "linear",\n'
        '  "unit": "unit_name"\n'
        "}\n"
        "```"
    )

    ai_response = await call_configured_ai_model(system_prompt, user_input, user_id=user_id)
    if ai_response:
        json_start = ai_response.find("```json\n") + len("```json\n")
        json_end = ai_response.find("\n```", json_start)
        json_data = ai_response[json_start:json_end].strip()

        try:
            refined_data = json.loads(json_data)
            return refined_data
        except json.JSONDecodeError as e:
            logging.error(f"JSONè§£æé”™è¯¯: {e}")
            return None
    else:
        logging.error("AIæœªèƒ½ç”Ÿæˆæœ‰æ•ˆçš„å›å¤")
        return None


async def generate_insight_analysis(user_input, df, user_id: int = 1):
    """
    ç”Ÿæˆæ•°æ®æ´å¯Ÿåˆ†æ

    Args:
        user_input: ç”¨æˆ·è¾“å…¥
        df: æŸ¥è¯¢ç»“æœDataFrame
        user_id: ç”¨æˆ·ID,ç”¨äºè·å–ç”¨æˆ·é€‰æ‹©çš„æ¨¡å‹é…ç½®

    Returns:
        æ´å¯Ÿåˆ†ææ–‡æœ¬
    """
    # åŠ¨æ€è·å–å½“å‰æ—¶é—´ä¿¡æ¯
    from datetime import datetime
    import pytz

    # è·å–ä¸­å›½æ—¶åŒºçš„å½“å‰æ—¶é—´
    china_tz = pytz.timezone('Asia/Shanghai')
    current_time = datetime.now(china_tz)
    current_date = current_time.strftime('%Y-%m-%d')
    current_year = current_time.year
    current_month = current_time.month

    system_prompt = (
        "åŸºäºç”¨æˆ·çš„é—®é¢˜å’ŒæŸ¥è¯¢ç»“æœï¼Œç”Ÿæˆæ·±å…¥çš„æ´å¯Ÿåˆ†æã€‚åˆ†æåº”è¯¥ç®€æ´æ˜äº†ï¼Œå¹¶æä¾›ä»æ•°æ®ä¸­å¾—å‡ºçš„æœ‰æ„ä¹‰çš„è§è§£ã€‚\n\n"
        f"å½“å‰æ—¶é—´ä¸Šä¸‹æ–‡ï¼šä»Šå¤©æ˜¯{current_date}ï¼Œå½“å‰å¹´ä»½æ˜¯{current_year}å¹´{current_month}æœˆ\n"
        f"æ•°æ®æ—¶é—´èŒƒå›´ï¼š2024å¹´6æœˆè‡³12æœˆ\n\n"
        f"ç”¨æˆ·é—®é¢˜ï¼š{user_input}\n\n"
        f"æŸ¥è¯¢ç»“æœï¼š\n{df.to_json(orient='records', force_ascii=False)}\n\n"
        "è¯·æŒ‰ç…§ä»¥ä¸‹Markdownæ ¼å¼è¿”å›åˆ†æç»“æœï¼š\n\n"
        "## ğŸ“Š æ•°æ®æ´å¯Ÿåˆ†æ\n\n"
        "### ğŸ” å…³é”®å‘ç°\n"
        "- **æ ¸å¿ƒæŒ‡æ ‡**ï¼š[æè¿°ä¸»è¦æ•°æ®æŒ‡æ ‡]\n"
        "- **æ•°æ®è¶‹åŠ¿**ï¼š[æè¿°æ•°æ®å˜åŒ–è¶‹åŠ¿]\n"
        "- **å¯¹æ¯”åˆ†æ**ï¼š[å¦‚æœ‰å¯¹æ¯”æ•°æ®ï¼Œè¿›è¡Œåˆ†æ]\n\n"
        "### ğŸ’¡ æ·±åº¦è§£è¯»\n"
        "[è¯¦ç»†åˆ†ææ•°æ®èƒŒåçš„åŸå› å’Œæ„ä¹‰]\n\n"
        "### ğŸ“ˆ ä¸šåŠ¡å¯ç¤º\n"
        "1. **çŸ­æœŸå½±å“**ï¼š[åˆ†æå¯¹å½“å‰çš„å½±å“]\n"
        "2. **é•¿æœŸè¶‹åŠ¿**ï¼š[é¢„æµ‹æœªæ¥å¯èƒ½çš„å‘å±•]\n"
        "3. **è¡ŒåŠ¨å»ºè®®**ï¼š[åŸºäºæ•°æ®æä¾›çš„å»ºè®®]\n\n"
        "### ğŸ¯ å…³æ³¨è¦ç‚¹\n"
        "> [é‡ç‚¹æé†’æˆ–éœ€è¦ç‰¹åˆ«å…³æ³¨çš„æ•°æ®ç‚¹]\n\n"
        "è¯·ç¡®ä¿åˆ†æå†…å®¹å‡†ç¡®ã€æœ‰è§åœ°ï¼Œå¹¶ä¸ç”¨æˆ·çš„é—®é¢˜ç´§å¯†ç›¸å…³ã€‚ä½¿ç”¨ä¸­æ–‡å›ç­”ã€‚"
    )

    ai_response = await call_configured_ai_model(system_prompt, user_input, user_id=user_id)
    if ai_response:
        # ç›´æ¥è¿”å›AIå“åº”ï¼Œä¸å†å¯»æ‰¾ç‰¹å®šæ ¼å¼æ ‡è®°
        # AIåº”è¯¥ç›´æ¥è¿”å›æ ¼å¼åŒ–çš„Markdownå†…å®¹
        return ai_response.strip()
    else:
        logging.error("AIæœªèƒ½ç”Ÿæˆæœ‰æ•ˆçš„æ´å¯Ÿåˆ†æ")
        return None


async def determine_chart_type(user_input, json_data, user_id: int = 1):
    """
    ç¡®å®šå›¾è¡¨ç±»å‹

    Args:
        user_input: ç”¨æˆ·è¾“å…¥
        json_data: JSONæ ¼å¼çš„æ•°æ®
        user_id: ç”¨æˆ·ID,ç”¨äºè·å–ç”¨æˆ·é€‰æ‹©çš„æ¨¡å‹é…ç½®

    Returns:
        å›¾è¡¨ç±»å‹
    """
    system_prompt = (
        "Based on the user's question and the provided data, determine the most appropriate chart type to visualize the data. "
        "The chart type should be returned as a string in markdown format.\n\n"
        "User's question: {user_input}\n\n"
        "Data:\n\n"
        f"{json_data}\n\n"
        "The chart type should be one of the following: 'bar', 'line', 'pie', 'scatter', 'histogram'.\n\n"
        "The response should be formatted as follows:\n\n"
        "```chart\n"
        "chart_type\n"
        "```"
    )

    ai_response = await call_configured_ai_model(system_prompt, user_input, user_id=user_id)
    if ai_response:
        chart_start = ai_response.find("```chart\n") + len("```chart\n")
        chart_end = ai_response.find("\n```", chart_start)
        chart_type = ai_response[chart_start:chart_end].strip()

        if chart_type in ["bar", "line", "pie", "scatter", "histogram"]:
            return chart_type
        else:
            logging.error("AIç”Ÿæˆçš„å›¾è¡¨ç±»å‹æ— æ•ˆ")
            return None
    else:
        logging.error("AIæœªèƒ½ç”Ÿæˆæœ‰æ•ˆçš„å›å¤")
        return None
